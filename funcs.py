#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue May 29 18:35:43 2018

@author: luoningqi
"""

import math
import numpy as np

''' cal activity function (sigmoid) '''
def activity(p):
    return 1/(1+math.e**(-p))

''' cal combinations '''
def zk(z,k,x):
    if k== 0:
        return z
    xx = x[k]
    su = 0
    for i in range(1,k+2):
        a = z**i
        b = a*xx[i]
        su += b
    return su

''' average(abs(output1-output2)) '''
def absCut(X1,X2,N):
    cou = 0
    for i in range(1,N+1):
        cou += abs(X1[i]-X2[i])
    return cou/N

''' average(abs(output)) '''  
def absAdd(X,N):
    cou = 0
    for i in range(1,N+1):
        cou += abs(X[i])
    return cou/N

''' variable for cal.ingcombinations '''
def getMatF():
    x = np.zeros((100,200))
    x[1][1] = 1
    x[1][2] = -1
    for i in range(2,80):
        for j in range(1,i+1):
            x[i][j] = float((x[i-1][j]-x[i-1][j-1])*j+x[i-1][j-1])
        x[i][i+1]=-1*x[i-1][i]*i
    return x

''' w,b init '''
def getRandomW(L,N):
    w = np.zeros((L+1,N+1,N+1))
    for i in range(L+1):
        for j in range(N+1):
            w[i][j] = np.random.uniform(-10,10,size=N+1)
    return w

''' randomly drop (simulation) '''
def drop(N,L,w):
    for l in range(1,L+1):
        for i in range(1,N+1):
            if np.random.randint(0,2)==0:# rate = 0.5
                w[l][i] = np.zeros((N+1))
    return w

''' cal xor 4 (noisy classification task) '''
def XOR4(a,b,c,d):
    return int((not a and b) or (c and (not d)))

''' record (noisy classification task) '''
def writeAns(testans,filename='a'):
    fp = open(filename,'w')
    for item in testans:
        fp.write(str(item)+'\n')
    fp.close()

def drawExpSensitivity():
    import matplotlib.pyplot as plt
    # raw data
    sen_FC = [[0.0000000000000000000,0.00021575102349978282,0.00043716377535628424,0.0006527660925899237,0.0008718740129275153,0.0010731120004503554,0.0013014413035707037,0.0015357410621813913,0.0017548538325017464,0.001889148259306217,0.002132299846236216],#N=4
              [0.0000000000000000000,0.00026178609778452426,0.0005089497687968349,0.0007577806709571202,0.0010622365096753814,0.0013142789123401762,0.0015773545151597642,0.001821097066217476,0.0020660258063498953,0.0023455346741328453,0.0025664306271754407],#N=8
              [0.0000000000000000000,0.0005156560356750266,0.0010228320240231524,0.001477827161533242,0.0019847068589801727,0.0024910943568647445,0.00307619718270751,0.0034535603931413654,0.0041441210487617175,0.004348687963949944,0.004973861843594183],#N=16
              [0.0000000000000000000,0.0014313596291125547,0.0029328471031106265,0.004294195125040329,0.005655885398643262,0.007032907675589439,0.008533635036483331,0.009891811945397603,0.011307843374406537,0.012804374173713714,0.013759880230911518]]#N=32
    # simulation
    sen_BC_S=[[0.0000000000000000000,0.00019500467188093314,0.0003850581430089277,0.0005779192525270582,0.0007733658018335312,0.000944033730190926,0.0011315011008884086,0.0013051938866367285,0.0015029185964552144,0.0016889997735930263,0.0018982278398577417],#N=4
              [0.0000000000000000000,0.00012038450064405076,0.0002320407893530417,0.00034737675603149564,0.0004633104477716908,0.0005854812763686825,0.0007193621982470526,0.00082970391707842,0.0009140668486132814,0.0010396190333197594,0.0011644982352620853],#N=8
              [0.0000000000000000000,7.64436085520261e-05,0.00014914355011166246,0.00022886566932756592,0.0002962592055419911,0.0003807767936700383,0.00044808658540111885,0.0005142417747004538,0.0005950057784938662,0.0006596892291358798,0.0007383473947552126],#N=16
              [0.0000000000000000000,4.9536698610901064e-05,9.874170304663794e-05,0.00014666655792147315,0.00019710708052783085,0.0002449952408421633,0.0002912211232899517,0.0003354269568026495,0.00038367455633816296,0.0004267649373914824,0.0004806847186511771]]#N=32
    # theoretical
    sen_BC_T=[[0.0000000000000000000,0.00016604787514616499,0.00032831389973774774,0.0004966838615598242,0.0006574868235708516,0.00082102098073885,0.000981120074810933,0.0011427155658708355,0.00130413766849605,0.0014641047581247272,0.0016243586718154546],#N=4
              [0.0000000000000000000,9.199521168249937e-05,0.00018450213170328808,0.0002759818616885683,0.00036573140025203263,0.0004564888028864736,0.0005464594751121894,0.0006405297780734767,0.0007265002307302502,0.0008194738636947736,0.0009151620864621101],#N=8
              [0.0000000000000000000,5.3325966935576274e-05,0.00010640814100812281,0.00015837349507928866,0.00021275849726563049,0.00026590252971495147,0.0003189936166072836,0.0003706972478867542,0.00042429610644624993,0.0004746098383199403,0.0005282036541051898],#N=16
              [0.0000000000000000000,3.157320302762667e-05,6.285490303434778e-05,9.413797393157213e-05,0.0001259971638255943,0.00015739812892315988,0.00018689399284011268,0.00021865252588060678,0.0002508427879641755,0.0002800477028048298,0.0003095064472553398]]#N=32
    # dropout p = 0.5
    sen_DP = [[0.0000000000000000000,6.743033314656627e-05,0.0001293818573774026,0.00019228463020633805,0.0002595338634327143,0.0003457288539675208,0.0004033335533535771,0.0004540693988669392,0.000555130327192889,0.0006025116187669309,0.0006731792094857868],
              [0.0000000000000000000,5.8508091151796326e-05,0.0001163050123830174,0.00017400711901943496,0.00022105256758848732,0.00027692661853466005,0.0003380496572827078,0.00037802205694589157,0.00044524574826420703,0.0005102948386819858,0.0005636562116444694],
              [0.0000000000000000000,8.09894832678979e-05,0.00016029663770770992,0.0002214735134317765,0.00030682029040609974,0.00040407687405448895,0.0004702071052936187,0.0005308340293844198,0.0006336627770465921,0.000646535255092577,0.0007904982393114793],
              [0.0000000000000000000,0.00017490713190336721,0.000349327791649687,0.000517594903754651,0.0007085741069551546,0.0008656284586695316,0.00099239726571902,0.0012106677036337666,0.0013994425997335507,0.0015280006239730324,0.0015996196874740669]]
    # locally connected k = 3
    sen_LC = [[0.0000000000000000000,0.000196757883756599,0.00038274007176648106,0.0005785074083242532,0.000772809796878675,0.0009618734604364606,0.0011678252185093763,0.001339147856712458,0.0015196818098537135,0.0016910063486400063,0.001886506674971592],
              [0.0000000000000000000,0.00013533449684678667,0.0002611928029084868,0.0003952429782950545,0.0005327002434743844,0.0006628565515414915,0.0008027411660285379,0.0009319128966002494,0.0010401928628932812,0.0011972706120603898,0.0013492954721872567],
              [0.0000000000000000000,9.90768361147211e-05,0.00019760308021372802,0.00029167966546649233,0.00038411099224929565,0.0004947336458068454,0.0005914434750473066,0.0006826736059634861,0.0007824757104896368,0.0008672018379523183,0.000965526412660782],
              [0.0000000000000000000,7.440717704205892e-05,0.00014832686905408198,0.00021333240277351178,0.00028672319451214506,0.0003612217054894893,0.00043779066062394565,0.0004973103621853404,0.0005720631330069048,0.0006516370145743247,0.0007159993390014307]]
    # draw
    t = np.arange(0., 1.1, 0.1)
    for i in range(4):
        plt.plot(t,sen_FC[i], 'Dr--', t, sen_BC_S[i], 'bs--', t, sen_BC_T[i], 'g^--',t,sen_DP[i], 'co--',t,sen_LC[i], 'm*--')
        plt.ylabel('Sensitivity')
        plt.xlabel('Input deviation(%)')
        plt.show()

def drawExpClassification(rawData):
    import matplotlib.pyplot as plt
    all_steps = 10000
    smooth = 20
    data = [[],[],[],[],[],[]]
    for i in range(all_steps):
        if i%smooth == 0:
            for j in range(6):
                data[j].append(np.average(rawData[j][i:i+smooth]))
    steps = np.arange(0, all_steps, smooth)
    plt.plot(steps, data[0], 'r', steps, data[1], 'b', steps, data[2], 'g', steps, data[3], 'c', steps, data[4], 'm', steps, data[5], 'y')
    plt.ylabel('Accuracy')
    plt.xlabel('Steps')
    plt.show()